# Photo

Unfortunately, photos (and any images in general) have long been easily recognized and indexed content.
Search engines can search for similar photos, distinguish text, objects, and specific people on them. Social
networks can recognize you in an arbitrary photo and put a mark there with a link to you even without your knowledge.

But, fortunately, in recent years, the trend towards privacy has intensified, and therefore social networks are introducing reasonable restrictions
on recognizing people. And search engines refuse to search for faces accurately at all. This reduces the likelihood of
malicious use of such functions, but does not prevent the use of such technologies in general.
Now recognition tools can be easily created independently or use shareware analogues.

*The section will be updated*

## How to test yourself

In the post-Soviet space, you can still use [Yandex](https://images.yandex.ru/).
Also, from the free specialized search engines, you can note [search4faces](https://search4faces.com/), which allows
you to search by photos from VKontakte, Odnoklassniki, TikTok, Clubhouse.

If you have actively used social networks, you can find not only your account, but also photos with your face
in the accounts of your friends, acquaintances or other people who are not even related to you. Of course,
it is extremely difficult to delete such photos, and if you do not want them to point at you, then you should competently [delete account](./deleteme.md).

<img width="1123" alt="image" src="https://user-images.githubusercontent.com/31013580/193446993-ae071840-49f2-45f3-b517-6b1e2a97a510.png">

## Face photo as biometrics

*The section will be updated*

### Cloaking

To combat the tools for recognizing people in images, so-called cloaking is used.
The essence of the method is to distort the photo in such a way that visually we perceive it as the original,
but the programs did not see a person or a face there.

Methods for distortion can be both manual (blurring / retouching / distortion of individual parts of the photo) and automatic.
Of the latter, special programs that use face recognition algorithms in the opposite direction can be noted,
modifying the photo so that the search is not possible. An example of such a program: [Fawkes](https://github.com/Shawn-Shan/fawkes).

Of course, such post-processing of photos or videos will not help proactively. To make it difficult to recognize faces with "smart cameras" in
real life, original and not very good ways are invented, examples can be read from the links at the end of the page.

## Photo metadata

*The section will be updated*

## Materials used and useful links

- [Big Brother is (so far) blind](https://habr.com/ru/post/586094/)
- [King's new makeup](https://telegra.ph/Novyj-makiyazh-korolya-07-14)
---

[⬅️ Back](./password.md) | [⏫ Table of contents](../README.md) | [➡️ Next](./breaches.md)
